<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="keywords" content="LLM Alignment, Religious Bias, Demographic Analysis, Asian Nations, AI Bias">
  <meta name="robots" content="index, follow">
  <meta name="description" content="Our study quantifies religious bias in open LLMs through demographic analysis across Asian nations, revealing potential hegemonic worldviews in AI outputs.">

  <meta property="og:title" content="Sometimes the Model doth Preach: Quantifying Religious Bias in Open LLMs through Demographic Analysis in Asian Nations"/>
  <meta property="og:description" content="Large Language Models (LLMs) are capable of generating opinions and propagating bias unknowingly, originating from unrepresentative and non-diverse data collection. We analyse generated opinions on religious identity, beliefs and practices across several nations and territories in Asia."/>
  <meta property="og:url" content="https://themodeldothpreach.github.io"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Sometimes the Model doth Preach: Quantifying Religious Bias in Open LLMs through Demographic Analysis in Asian Nations">
  <meta name="twitter:description" content="Large Language Models (LLMs) are capable of generating opinions and propagating bias unknowingly, originating from unrepresentative and non-diverse data collection. We analyse generated opinions on religious identity, beliefs and practices across several nations and territories in Asia.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="LLM Alignment, Religious Bias, Demographic Analysis, Asian Nations, LLMOpinions">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Sometimes the Model doth Preach: Quantifying Religious Bias in Open LLMs through Demographic Analysis in Asian Nations</title>
  
  <!-- Favicons -->
  <link rel="apple-touch-icon" sizes="180x180" href="static/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="static/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="static/images/favicon-16x16.png">
  <link rel="manifest" href="static/images/site.webmanifest">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <style>
    .center-select {
      display: flex;
      justify-content: center;
      align-items: center;
    }
  </style>
  
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Sometimes the Model doth Preach: Quantifying Religious Bias in Open LLMs through Demographic Analysis in Asian Nations</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://harishankar08.github.io/" target="_blank">Hari Shankar</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://vedantasp.framer.website" target="_blank">Vedanta S P</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.linkedin.com/in/tejas-cavale-ba0498a3/" target="_blank">Tejas Cavale</a><sup>1</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="https://precog.iiit.ac.in" target="_blank">Ponnurangam Kumaraguru</a><sup>1</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="https://cse.iitkgp.ac.in/~abhijnan/" target="_blank">Abhijnan Chakraborty</a><sup>3</sup></span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>IIIT Hyderabad,<sup>2</sup>IIIT Kottayam,<sup>3</sup>IIT Kharagpur
                    </span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/HariShankar08/LLMOpinions" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
 <!-- TODO: let's put the dropdown globe select thing here. -->
 <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        We present the Model Profiles for each country/territory surveyed through the map below. 
      </h2>

      <img id="teaserImage" src="static/images/Religion.jpeg" alt="Religion" class="teaser-image">
      <h2 id="teaserCaption" class="subtitle has-text-centered">
        The Model Profiles reflect the Religious Majorities of each Country/Territory surveyed. 
      </h2>

      <div class="center-select">
        <div class="select is-info">
          <select id="categorySelect" class="select">
            <option value="Religion" selected>Religion</option>
            <option value="Age">Age</option>
            <option value="Gender">Gender</option>
            <option value="Education">Education Level</option>
          </select>
        </div>
      </div>
      <br>

      <h3 class="subtitle has-text-centered">
        Use the above dropdown to view the Model Profiles for different demographic categories. 
      </h2>

    </div>
  </div>
</section>

<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Language Models (LLMs) are capable of generating
            opinions and propagating bias unknowingly, originating from
            unrepresentative and non-diverse data collection. Prior research has analysed these opinions with respect to the West,
            particularly the United States. However, insights thus produced may not be generalized in non-Western populations.
            With the widespread usage of LLM systems by users across
            several different walks of life, the cultural sensitivity of each
            generated output is of crucial interest. Our work proposes a
            novel method that quantitatively analyzes the opinions generated by LLMs, improving on previous work with regards
            to extracting the social demographics of the models. Our
            method measures the distance from an LLM’s response to
            survey respondents, through Hamming Distance, to infer the
            demographic characteristics reflected in the model’s outputs.
            We evaluate modern, open LLMs such as Llama and Mistral
            on surveys conducted in various global south countries, with a
            focus on India and other Asian nations, specifically assessing
            the model’s performance on surveys related to religious tolerance and identity. Our analysis reveals that most open LLMs
            match a single homogeneous profile, varying across different
            countries/territories, which in turn raises questions about the
            risks of LLMs promoting a hegemonic worldview, and undermining perspectives of different minorities. Our framework
            may also be useful for future research investigating the complex intersection between training data, model architecture,
            and the resulting biases reflected in LLM outputs, particularly concerning sensitive topics like religious tolerance and
            identity.  
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Datasets</h2>
        <div class="content has-text-justified">
          <p>
            We use three publicly available survey datasets provided by Pew Research Center, covering topics on religious beliefs, identity and tolerance across Asian nations;
             the India Survey Dataset, provided by Sahgal and Evans (<a href="https://www.pewresearch.org/religion/dataset/india-survey-dataset/" target="_blank">linked here</a>), the East Asian 
             Societies Survey Dataset, provided by Evans (<a href="https://www.pewresearch.org/dataset/east-asian-societies-survey-dataset/" target="_blank">linked here</a>) and the South and Southeast
             Asia Survey Dataset, provided by Evans (<a href="https://www.pewresearch.org/dataset/south-and-southeast-asia-survey-dataset/"target="_blank">linked here</a>).
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Computing Similarity of Responses</h2>
        <div class="content has-text-justified">
          <p>
            We profile LLMs by comparing their responses to survey data using the Hamming Distance metric. Each question is paraphrased and each version of the question is used in prompting each model, to account for prompt sensitivity. The most frequent response among these is then selected as the model’s final answer. We use the Hamming Distance between the 
            model's response and real survey respondents to sort respondents, following which a demographic profile is generated for each LLM, capturing its alignment with specific population segments. This method allows for a holistic profiling approach that considers interconnected demographic traits rather than isolating individual variables.  
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">The Overall Sameness of Model Profiles</h2>
        <div class="content has-text-justified">
          <p>
            We note that all models (from the Llama, Mistral and Gemma families) tested in the study exhibit a high degree of similarity in their demographic profiles. This is observed despite differences in their architectures, parameter sizes, and training methodologies. This models, even when developed by different organizations, tend to reflect similar socio-demographic characteristics, which may vary across countries/territories.  
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Ineffective Zero-Shot Steering</h2>
        <div class="content has-text-justified">
          <p>
            We test different zero-shot steering methods (i.e., prompting models to respond as though they belong to different demographic groups), but find that these approaches fail to meaningfully alter the underlying demographic profile. Other approaches such as fine-tuning and model augmentation may provide better results.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        -->
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<script>
  document.getElementById('categorySelect').addEventListener('change', function() {
    const category = this.value;
    const imageElement = document.getElementById('teaserImage');
    const captionElement = document.getElementById('teaserCaption');
    
    const data = {
      Religion: {
        img: "static/images/Religion.jpeg",
        caption: "The Model Profiles reflect the Religious Majorities of each Country/Territory surveyed."
      },
      Age: {
        img: "static/images/Age.jpeg",
        caption: "The Model Profiles indicate closer alignment to older age groups for most countries."
      },
      Gender: {
        img: "static/images/Gender.jpeg",
        caption: "Most Models are closely aligned to Male respondents, with the exception of Cambodia, Thailand and Vietnam."
      },
      Education: {
        img: "static/images/Education_Level.jpeg",
        caption: "In most countries surveyed, the Model Profiles indicate close alignment to respondents who finished Upper/Senior Secondary Schooling."
      }
    };
    
    imageElement.src = data[category].img;
    imageElement.alt = category;
    captionElement.textContent = data[category].caption;
  });
</script>


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>